{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (12223, 28, 28, 1)\n",
      "12223 train samples\n",
      "2060 test samples\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import *\n",
    "import numpy as np\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#Only look at 2s and 7s\n",
    "num_classes = 2\n",
    "train_picks = np.logical_or(y_train==2,y_train==7)\n",
    "test_picks = np.logical_or(y_test==2,y_test==7)\n",
    "\n",
    "x_train = x_train[train_picks]\n",
    "x_test = x_test[test_picks]\n",
    "y_train = np.array(y_train[train_picks]==7,dtype=int)\n",
    "y_test = np.array(y_test[test_picks]==7,dtype=int)\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function that Allows the GridSearch to change the model\n",
    "def create_model(activator='relu', dropout_rate1=.25, dropout_rate2=.25, \n",
    "                 _optimizer='Adam', batch_size=128, epochs=12, neurons=16, learning_rate=.001):\n",
    "    \n",
    "    #This allows you to tune Optimizer & Learning Rate at the Same Time\n",
    "    if _optimizer == 'Adam':\n",
    "        optimizer = Adam(lr=learning_rate)\n",
    "    elif _optimizer == 'SGD':\n",
    "        optimizer = SGD(lr=learning_rate)\n",
    "    elif _optimizer == 'Adamax':\n",
    "        optimizer = Adamax(lr=learning_rate)\n",
    "    else:\n",
    "        optimizer = Nadam(lr=learning_rate)\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(4, kernel_size=(3, 3),activation=activator,input_shape=input_shape))\n",
    "    model.add(Conv2D(8, (3, 3), activation=activator))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(neurons, activation=activator))\n",
    "    model.add(Dropout(dropout_rate2))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "8148/8148 [==============================] - 4s - loss: 0.1035 - acc: 0.9703     \n",
      "Epoch 2/8\n",
      "8148/8148 [==============================] - 3s - loss: 0.0542 - acc: 0.9826     \n",
      "Epoch 3/8\n",
      "8148/8148 [==============================] - 3s - loss: 0.0379 - acc: 0.9891     \n",
      "Epoch 4/8\n",
      "8148/8148 [==============================] - 3s - loss: 0.0369 - acc: 0.9876     \n",
      "Epoch 5/8\n",
      "8148/8148 [==============================] - 4s - loss: 0.0355 - acc: 0.9883     \n",
      "Epoch 6/8\n",
      "8148/8148 [==============================] - 4s - loss: 0.0332 - acc: 0.9912     \n",
      "Epoch 7/8\n",
      "8148/8148 [==============================] - 4s - loss: 0.0320 - acc: 0.9901     \n",
      "Epoch 8/8\n",
      "8148/8148 [==============================] - 4s - loss: 0.0293 - acc: 0.9915     \n",
      "8000/8148 [============================>.] - ETA: 0sEpoch 1/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.0827 - acc: 0.9731     \n",
      "Epoch 2/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0439 - acc: 0.9853     \n",
      "Epoch 3/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0330 - acc: 0.9893     \n",
      "Epoch 4/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0315 - acc: 0.9902     \n",
      "Epoch 5/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0271 - acc: 0.9907     \n",
      "Epoch 6/8\n",
      "8149/8149 [==============================] - 3s - loss: 0.0248 - acc: 0.9917     \n",
      "Epoch 7/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0273 - acc: 0.9904     \n",
      "Epoch 8/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0247 - acc: 0.9923     \n",
      "8000/8149 [============================>.] - ETA: 0sEpoch 1/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.0837 - acc: 0.9692     \n",
      "Epoch 2/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0472 - acc: 0.9852     - ETA: 0s - loss: 0.0484 - acc\n",
      "Epoch 3/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0388 - acc: 0.9867     \n",
      "Epoch 4/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0335 - acc: 0.9903     \n",
      "Epoch 5/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0297 - acc: 0.9910     \n",
      "Epoch 6/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0276 - acc: 0.9909     \n",
      "Epoch 7/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0236 - acc: 0.9929     \n",
      "Epoch 8/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0258 - acc: 0.9919     \n",
      "8064/8149 [============================>.] - ETA: 0sEpoch 1/12\n",
      "8148/8148 [==============================] - 15s - loss: 0.5042 - acc: 0.7478    \n",
      "Epoch 2/12\n",
      "8148/8148 [==============================] - 14s - loss: 0.2903 - acc: 0.8476    \n",
      "Epoch 3/12\n",
      "8148/8148 [==============================] - 14s - loss: 0.2412 - acc: 0.8559    \n",
      "Epoch 4/12\n",
      "8148/8148 [==============================] - 14s - loss: 0.2338 - acc: 0.8563    \n",
      "Epoch 5/12\n",
      "8148/8148 [==============================] - 14s - loss: 0.2225 - acc: 0.8592    \n",
      "Epoch 6/12\n",
      "8148/8148 [==============================] - 14s - loss: 0.2211 - acc: 0.8597    \n",
      "Epoch 7/12\n",
      "8148/8148 [==============================] - 14s - loss: 0.2168 - acc: 0.8660    \n",
      "Epoch 8/12\n",
      "8148/8148 [==============================] - 14s - loss: 0.2186 - acc: 0.8560    \n",
      "Epoch 9/12\n",
      "8148/8148 [==============================] - 14s - loss: 0.1991 - acc: 0.8845    \n",
      "Epoch 10/12\n",
      "8148/8148 [==============================] - 14s - loss: 0.1749 - acc: 0.9498    \n",
      "Epoch 11/12\n",
      "8148/8148 [==============================] - 14s - loss: 0.1615 - acc: 0.9480    \n",
      "Epoch 12/12\n",
      "8148/8148 [==============================] - 14s - loss: 0.1567 - acc: 0.9578    \n",
      "8064/8148 [============================>.] - ETA: 0sEpoch 1/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.4445 - acc: 0.7708    \n",
      "Epoch 2/12\n",
      "8149/8149 [==============================] - 15s - loss: 0.2631 - acc: 0.8770    \n",
      "Epoch 3/12\n",
      "8149/8149 [==============================] - 15s - loss: 0.2351 - acc: 0.8741    \n",
      "Epoch 4/12\n",
      "8149/8149 [==============================] - 15s - loss: 0.1925 - acc: 0.9470    \n",
      "Epoch 5/12\n",
      "8149/8149 [==============================] - 14s - loss: 0.1826 - acc: 0.9480    \n",
      "Epoch 6/12\n",
      "8149/8149 [==============================] - 14s - loss: 0.1592 - acc: 0.9536    \n",
      "Epoch 7/12\n",
      "8149/8149 [==============================] - 15s - loss: 0.1463 - acc: 0.9578    \n",
      "Epoch 8/12\n",
      "8149/8149 [==============================] - 14s - loss: 0.1511 - acc: 0.9523    \n",
      "Epoch 9/12\n",
      "8149/8149 [==============================] - 15s - loss: 0.1567 - acc: 0.9493    \n",
      "Epoch 10/12\n",
      "8149/8149 [==============================] - 15s - loss: 0.1439 - acc: 0.9531    \n",
      "Epoch 11/12\n",
      "8149/8149 [==============================] - 15s - loss: 0.1273 - acc: 0.9610    \n",
      "Epoch 12/12\n",
      "8149/8149 [==============================] - 15s - loss: 0.1306 - acc: 0.9583    \n",
      "8128/8149 [============================>.] - ETA: 0sEpoch 1/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.5239 - acc: 0.7214    \n",
      "Epoch 2/12\n",
      "8149/8149 [==============================] - 14s - loss: 0.2770 - acc: 0.8605    \n",
      "Epoch 3/12\n",
      "8149/8149 [==============================] - 14s - loss: 0.2356 - acc: 0.8672    \n",
      "Epoch 4/12\n",
      "8149/8149 [==============================] - 15s - loss: 0.2234 - acc: 0.8688    \n",
      "Epoch 5/12\n",
      "8149/8149 [==============================] - 15s - loss: 0.2230 - acc: 0.8633    \n",
      "Epoch 6/12\n",
      "8149/8149 [==============================] - 15s - loss: 0.2236 - acc: 0.8656    \n",
      "Epoch 7/12\n",
      "8149/8149 [==============================] - 15s - loss: 0.2237 - acc: 0.8619    \n",
      "Epoch 8/12\n",
      "8149/8149 [==============================] - 14s - loss: 0.2190 - acc: 0.8594    \n",
      "Epoch 9/12\n",
      "8149/8149 [==============================] - 14s - loss: 0.2133 - acc: 0.8704    \n",
      "Epoch 10/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.2117 - acc: 0.8752    \n",
      "Epoch 11/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.2138 - acc: 0.8651    \n",
      "Epoch 12/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.2140 - acc: 0.8649    \n",
      "8128/8149 [============================>.] - ETA: 0sEpoch 1/12\n",
      "8148/8148 [==============================] - 16s - loss: 0.6932 - acc: 0.5025    \n",
      "Epoch 2/12\n",
      "8148/8148 [==============================] - 16s - loss: 0.6937 - acc: 0.4968    \n",
      "Epoch 3/12\n",
      "8148/8148 [==============================] - 23s - loss: 0.6937 - acc: 0.5012    \n",
      "Epoch 4/12\n",
      "8148/8148 [==============================] - 20s - loss: 0.6936 - acc: 0.5049    \n",
      "Epoch 5/12\n",
      "8148/8148 [==============================] - 20s - loss: 0.6936 - acc: 0.5022    \n",
      "Epoch 6/12\n",
      "8148/8148 [==============================] - 18s - loss: 0.6937 - acc: 0.4964    \n",
      "Epoch 7/12\n",
      "8148/8148 [==============================] - 17s - loss: 0.6935 - acc: 0.5029    \n",
      "Epoch 8/12\n",
      "8148/8148 [==============================] - 17s - loss: 0.6931 - acc: 0.5054    \n",
      "Epoch 9/12\n",
      "8148/8148 [==============================] - 18s - loss: 0.6937 - acc: 0.4971    \n",
      "Epoch 10/12\n",
      "8148/8148 [==============================] - 19s - loss: 0.6931 - acc: 0.5090    \n",
      "Epoch 11/12\n",
      "8148/8148 [==============================] - 17s - loss: 0.6941 - acc: 0.4963    \n",
      "Epoch 12/12\n",
      "8148/8148 [==============================] - 16s - loss: 0.6935 - acc: 0.5081    \n",
      "8112/8148 [============================>.] - ETA: 0sEpoch 1/12\n",
      "8149/8149 [==============================] - 22s - loss: 0.6945 - acc: 0.4912    \n",
      "Epoch 2/12\n",
      "8149/8149 [==============================] - 17s - loss: 0.6936 - acc: 0.5026    \n",
      "Epoch 3/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6928 - acc: 0.5111    \n",
      "Epoch 4/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6927 - acc: 0.5102    \n",
      "Epoch 5/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6931 - acc: 0.5115    \n",
      "Epoch 6/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6922 - acc: 0.5179    \n",
      "Epoch 7/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6931 - acc: 0.5095    \n",
      "Epoch 8/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6930 - acc: 0.5090    \n",
      "Epoch 9/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6929 - acc: 0.5106    \n",
      "Epoch 10/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6924 - acc: 0.5198    \n",
      "Epoch 11/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6930 - acc: 0.5149    \n",
      "Epoch 12/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6931 - acc: 0.5186    \n",
      "8149/8149 [==============================] - 4s     \n",
      "Epoch 1/12\n",
      "8149/8149 [==============================] - 17s - loss: 0.6941 - acc: 0.5089    \n",
      "Epoch 2/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6936 - acc: 0.5106    \n",
      "Epoch 3/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6932 - acc: 0.5129    \n",
      "Epoch 4/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6940 - acc: 0.5057    \n",
      "Epoch 5/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6936 - acc: 0.5033    \n",
      "Epoch 6/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6935 - acc: 0.5075    \n",
      "Epoch 7/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6934 - acc: 0.5063    \n",
      "Epoch 8/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6935 - acc: 0.5099    \n",
      "Epoch 9/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6932 - acc: 0.5062    \n",
      "Epoch 10/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6933 - acc: 0.5138    \n",
      "Epoch 11/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6933 - acc: 0.5051    \n",
      "Epoch 12/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6935 - acc: 0.5048    \n",
      "8096/8149 [============================>.] - ETA: 0sEpoch 1/8\n",
      "8148/8148 [==============================] - 5s - loss: 0.0963 - acc: 0.9714     \n",
      "Epoch 2/8\n",
      "8148/8148 [==============================] - 3s - loss: 0.0411 - acc: 0.9863     \n",
      "Epoch 3/8\n",
      "8148/8148 [==============================] - 3s - loss: 0.0345 - acc: 0.9886     \n",
      "Epoch 4/8\n",
      "8148/8148 [==============================] - 3s - loss: 0.0303 - acc: 0.9897     \n",
      "Epoch 5/8\n",
      "8148/8148 [==============================] - 3s - loss: 0.0241 - acc: 0.9926     \n",
      "Epoch 6/8\n",
      "8148/8148 [==============================] - 3s - loss: 0.0215 - acc: 0.9929     \n",
      "Epoch 7/8\n",
      "8148/8148 [==============================] - 3s - loss: 0.0185 - acc: 0.9941     \n",
      "Epoch 8/8\n",
      "8148/8148 [==============================] - 3s - loss: 0.0156 - acc: 0.9946     \n",
      "8064/8148 [============================>.] - ETA: 0sEpoch 1/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0904 - acc: 0.9688     \n",
      "Epoch 2/8\n",
      "8149/8149 [==============================] - 3s - loss: 0.0354 - acc: 0.9869     \n",
      "Epoch 3/8\n",
      "8149/8149 [==============================] - 3s - loss: 0.0238 - acc: 0.9910     - ETA: 1s - los\n",
      "Epoch 4/8\n",
      "8149/8149 [==============================] - 3s - loss: 0.0171 - acc: 0.9942     \n",
      "Epoch 5/8\n",
      "8149/8149 [==============================] - 3s - loss: 0.0145 - acc: 0.9951     \n",
      "Epoch 6/8\n",
      "8149/8149 [==============================] - 3s - loss: 0.0114 - acc: 0.9971     \n",
      "Epoch 7/8\n",
      "8149/8149 [==============================] - 3s - loss: 0.0094 - acc: 0.9968     \n",
      "Epoch 8/8\n",
      "8149/8149 [==============================] - 3s - loss: 0.0090 - acc: 0.9974     \n",
      "8064/8149 [============================>.] - ETA: 0sEpoch 1/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0844 - acc: 0.9702     \n",
      "Epoch 2/8\n",
      "8149/8149 [==============================] - 3s - loss: 0.0352 - acc: 0.9882     \n",
      "Epoch 3/8\n",
      "8149/8149 [==============================] - 3s - loss: 0.0250 - acc: 0.9919     \n",
      "Epoch 4/8\n",
      "8149/8149 [==============================] - 3s - loss: 0.0197 - acc: 0.9944     \n",
      "Epoch 5/8\n",
      "8149/8149 [==============================] - 3s - loss: 0.0156 - acc: 0.9956     \n",
      "Epoch 6/8\n",
      "8149/8149 [==============================] - 3s - loss: 0.0128 - acc: 0.9960     \n",
      "Epoch 7/8\n",
      "8149/8149 [==============================] - 3s - loss: 0.0124 - acc: 0.9963     \n",
      "Epoch 8/8\n",
      "8149/8149 [==============================] - 3s - loss: 0.0096 - acc: 0.9973     - ETA: 0s - loss: 0.0087 - acc: 0\n",
      "4074/4074 [==============================] - 1s     \n",
      "8149/8149 [==============================] - 1s     \n",
      "Epoch 1/4\n",
      "8148/8148 [==============================] - 8s - loss: 0.2720 - acc: 0.8770     \n",
      "Epoch 2/4\n",
      "8148/8148 [==============================] - 7s - loss: 0.0703 - acc: 0.9775     \n",
      "Epoch 3/4\n",
      "8148/8148 [==============================] - 7s - loss: 0.0553 - acc: 0.9810     \n",
      "Epoch 4/4\n",
      "8148/8148 [==============================] - 7s - loss: 0.0523 - acc: 0.9821     \n",
      "8088/8148 [============================>.] - ETA: 0sEpoch 1/4\n",
      "8149/8149 [==============================] - 8s - loss: 0.3572 - acc: 0.7987     \n",
      "Epoch 2/4\n",
      "8149/8149 [==============================] - 7s - loss: 0.0661 - acc: 0.9810     \n",
      "Epoch 3/4\n",
      "8149/8149 [==============================] - 7s - loss: 0.0517 - acc: 0.9829     \n",
      "Epoch 4/4\n",
      "8149/8149 [==============================] - 7s - loss: 0.0455 - acc: 0.9853     \n",
      "8104/8149 [============================>.] - ETA: 0sEpoch 1/4\n",
      "8149/8149 [==============================] - 8s - loss: 0.2994 - acc: 0.8822     \n",
      "Epoch 2/4\n",
      "8149/8149 [==============================] - 7s - loss: 0.0832 - acc: 0.9779     \n",
      "Epoch 3/4\n",
      "8149/8149 [==============================] - 7s - loss: 0.0602 - acc: 0.9827     \n",
      "Epoch 4/4\n",
      "8149/8149 [==============================] - 7s - loss: 0.0519 - acc: 0.9850     \n",
      "4074/4074 [==============================] - 2s     \n",
      "8136/8149 [============================>.] - ETA: 0sEpoch 1/8\n",
      "8148/8148 [==============================] - 5s - loss: 0.0881 - acc: 0.9701     - ETA: 0s - loss: 0.0931 - a\n",
      "Epoch 2/8\n",
      "8148/8148 [==============================] - 3s - loss: 0.0460 - acc: 0.9858     \n",
      "Epoch 3/8\n",
      "8148/8148 [==============================] - 4s - loss: 0.0373 - acc: 0.9876     \n",
      "Epoch 4/8\n",
      "8148/8148 [==============================] - 3s - loss: 0.0339 - acc: 0.9890     \n",
      "Epoch 5/8\n",
      "8148/8148 [==============================] - 4s - loss: 0.0292 - acc: 0.9910     \n",
      "Epoch 6/8\n",
      "8148/8148 [==============================] - 5s - loss: 0.0293 - acc: 0.9907     \n",
      "Epoch 7/8\n",
      "8148/8148 [==============================] - 4s - loss: 0.0274 - acc: 0.9905     \n",
      "Epoch 8/8\n",
      "8148/8148 [==============================] - 4s - loss: 0.0232 - acc: 0.9924     \n",
      "8000/8148 [============================>.] - ETA: 0sEpoch 1/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.0753 - acc: 0.9747     \n",
      "Epoch 2/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.0363 - acc: 0.9880     \n",
      "Epoch 3/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.0249 - acc: 0.9923     \n",
      "Epoch 4/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0176 - acc: 0.9944     \n",
      "Epoch 5/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0150 - acc: 0.9953     \n",
      "Epoch 6/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0148 - acc: 0.9953     \n",
      "Epoch 7/8\n",
      "8149/8149 [==============================] - 3s - loss: 0.0133 - acc: 0.9958     \n",
      "Epoch 8/8\n",
      "8149/8149 [==============================] - 3s - loss: 0.0112 - acc: 0.9971     \n",
      "8000/8149 [============================>.] - ETA: 0sEpoch 1/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.0781 - acc: 0.9737     \n",
      "Epoch 2/8\n",
      "8149/8149 [==============================] - 3s - loss: 0.0360 - acc: 0.9891     \n",
      "Epoch 3/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0285 - acc: 0.9912     \n",
      "Epoch 4/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.0239 - acc: 0.9928     \n",
      "Epoch 5/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0223 - acc: 0.9930     \n",
      "Epoch 6/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0171 - acc: 0.9947     \n",
      "Epoch 7/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0165 - acc: 0.9944     \n",
      "Epoch 8/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0147 - acc: 0.9962     \n",
      "8064/8149 [============================>.] - ETA: 0sEpoch 1/12\n",
      "8148/8148 [==============================] - 21s - loss: 0.6936 - acc: 0.4915    \n",
      "Epoch 2/12\n",
      "8148/8148 [==============================] - 18s - loss: 0.6932 - acc: 0.4985    \n",
      "Epoch 3/12\n",
      "8148/8148 [==============================] - 18s - loss: 0.6930 - acc: 0.5085    \n",
      "Epoch 4/12\n",
      "8148/8148 [==============================] - 18s - loss: 0.6930 - acc: 0.5085    \n",
      "Epoch 5/12\n",
      "8148/8148 [==============================] - 18s - loss: 0.6930 - acc: 0.5085    \n",
      "Epoch 6/12\n",
      "8148/8148 [==============================] - 18s - loss: 0.6930 - acc: 0.5085    \n",
      "Epoch 7/12\n",
      "8148/8148 [==============================] - 18s - loss: 0.6930 - acc: 0.5085    \n",
      "Epoch 8/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8148/8148 [==============================] - 16s - loss: 0.6930 - acc: 0.5085    \n",
      "Epoch 9/12\n",
      "8148/8148 [==============================] - 17s - loss: 0.6929 - acc: 0.5085    \n",
      "Epoch 10/12\n",
      "8148/8148 [==============================] - 16s - loss: 0.6929 - acc: 0.5085    - ETA: 0s - loss: 0.6930 - acc\n",
      "Epoch 11/12\n",
      "8148/8148 [==============================] - 16s - loss: 0.6929 - acc: 0.5085    \n",
      "Epoch 12/12\n",
      "8148/8148 [==============================] - 16s - loss: 0.6929 - acc: 0.5085    \n",
      "8148/8148 [==============================] - 4s     \n",
      "Epoch 1/12\n",
      "8149/8149 [==============================] - 18s - loss: 0.6930 - acc: 0.5163    \n",
      "Epoch 2/12\n",
      "8149/8149 [==============================] - 17s - loss: 0.6928 - acc: 0.5177    \n",
      "Epoch 3/12\n",
      "8149/8149 [==============================] - 17s - loss: 0.6927 - acc: 0.5177    \n",
      "Epoch 4/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6927 - acc: 0.5177    \n",
      "Epoch 5/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6926 - acc: 0.5177    \n",
      "Epoch 6/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6926 - acc: 0.5177    - ETA: 1s - lo\n",
      "Epoch 7/12\n",
      "8149/8149 [==============================] - 17s - loss: 0.6926 - acc: 0.5177    \n",
      "Epoch 8/12\n",
      "8149/8149 [==============================] - 17s - loss: 0.6926 - acc: 0.5177    \n",
      "Epoch 9/12\n",
      "8149/8149 [==============================] - 17s - loss: 0.6926 - acc: 0.5177    \n",
      "Epoch 10/12\n",
      "8149/8149 [==============================] - 17s - loss: 0.6926 - acc: 0.5177    \n",
      "Epoch 11/12\n",
      "8149/8149 [==============================] - 17s - loss: 0.6926 - acc: 0.5177    \n",
      "Epoch 12/12\n",
      "8149/8149 [==============================] - 16s - loss: 0.6926 - acc: 0.5177    \n",
      "8128/8149 [============================>.] - ETA: 0sEpoch 1/12\n",
      "8149/8149 [==============================] - 18s - loss: 0.6931 - acc: 0.5115    \n",
      "Epoch 2/12\n",
      "8149/8149 [==============================] - 18s - loss: 0.6930 - acc: 0.5115    \n",
      "Epoch 3/12\n",
      "8149/8149 [==============================] - 17s - loss: 0.6929 - acc: 0.5115    \n",
      "Epoch 4/12\n",
      "8149/8149 [==============================] - 17s - loss: 0.6929 - acc: 0.5115    \n",
      "Epoch 5/12\n",
      "8149/8149 [==============================] - 17s - loss: 0.6929 - acc: 0.5115    \n",
      "Epoch 6/12\n",
      "8149/8149 [==============================] - 17s - loss: 0.6929 - acc: 0.5115    \n",
      "Epoch 7/12\n",
      "8149/8149 [==============================] - 17s - loss: 0.6929 - acc: 0.5115    \n",
      "Epoch 8/12\n",
      "8149/8149 [==============================] - 17s - loss: 0.6929 - acc: 0.5115    \n",
      "Epoch 9/12\n",
      "8149/8149 [==============================] - 17s - loss: 0.6929 - acc: 0.5115    \n",
      "Epoch 10/12\n",
      "8149/8149 [==============================] - 19s - loss: 0.6929 - acc: 0.5115    \n",
      "Epoch 11/12\n",
      "8149/8149 [==============================] - 24s - loss: 0.6929 - acc: 0.5115    \n",
      "Epoch 12/12\n",
      "8149/8149 [==============================] - 22s - loss: 0.6929 - acc: 0.5115    \n",
      "8112/8149 [============================>.] - ETA: 0sEpoch 1/4\n",
      "8148/8148 [==============================] - 6s - loss: 0.7317 - acc: 0.4968     \n",
      "Epoch 2/4\n",
      "8148/8148 [==============================] - 4s - loss: 0.7105 - acc: 0.5064     \n",
      "Epoch 3/4\n",
      "8148/8148 [==============================] - 5s - loss: 0.7093 - acc: 0.4983     \n",
      "Epoch 4/4\n",
      "8148/8148 [==============================] - 4s - loss: 0.7072 - acc: 0.4969     \n",
      "8064/8148 [============================>.] - ETA: 0sEpoch 1/4\n",
      "8149/8149 [==============================] - 5s - loss: 0.7246 - acc: 0.5026     \n",
      "Epoch 2/4\n",
      "8149/8149 [==============================] - 4s - loss: 0.7133 - acc: 0.5001     \n",
      "Epoch 3/4\n",
      "8149/8149 [==============================] - 3s - loss: 0.7089 - acc: 0.5056     \n",
      "Epoch 4/4\n",
      "8149/8149 [==============================] - 4s - loss: 0.7056 - acc: 0.5048     \n",
      "8064/8149 [============================>.] - ETA: 0sEpoch 1/4\n",
      "8149/8149 [==============================] - 5s - loss: 0.7343 - acc: 0.5068     \n",
      "Epoch 2/4\n",
      "8149/8149 [==============================] - 3s - loss: 0.7152 - acc: 0.4997     \n",
      "Epoch 3/4\n",
      "8149/8149 [==============================] - 3s - loss: 0.7073 - acc: 0.5017     \n",
      "Epoch 4/4\n",
      "8149/8149 [==============================] - 4s - loss: 0.7062 - acc: 0.4979     \n",
      "8064/8149 [============================>.] - ETA: 0sEpoch 1/12\n",
      "8148/8148 [==============================] - 10s - loss: 0.0568 - acc: 0.9806    \n",
      "Epoch 2/12\n",
      "8148/8148 [==============================] - 11s - loss: 0.0371 - acc: 0.9874    \n",
      "Epoch 3/12\n",
      "8148/8148 [==============================] - 10s - loss: 0.0328 - acc: 0.9896    \n",
      "Epoch 4/12\n",
      "8148/8148 [==============================] - 9s - loss: 0.0294 - acc: 0.9901     \n",
      "Epoch 5/12\n",
      "8148/8148 [==============================] - 9s - loss: 0.0269 - acc: 0.9905     \n",
      "Epoch 6/12\n",
      "8148/8148 [==============================] - 8s - loss: 0.0238 - acc: 0.9918     \n",
      "Epoch 7/12\n",
      "8148/8148 [==============================] - 8s - loss: 0.0219 - acc: 0.9920     \n",
      "Epoch 8/12\n",
      "8148/8148 [==============================] - 8s - loss: 0.0214 - acc: 0.9929     \n",
      "Epoch 9/12\n",
      "8148/8148 [==============================] - 9s - loss: 0.0191 - acc: 0.9925     \n",
      "Epoch 10/12\n",
      "8148/8148 [==============================] - 8s - loss: 0.0185 - acc: 0.9937     \n",
      "Epoch 11/12\n",
      "8148/8148 [==============================] - 9s - loss: 0.0177 - acc: 0.9937     \n",
      "Epoch 12/12\n",
      "8148/8148 [==============================] - 9s - loss: 0.0159 - acc: 0.9940     \n",
      "8144/8148 [============================>.] - ETA: 0sEpoch 1/12\n",
      "8149/8149 [==============================] - 10s - loss: 0.0621 - acc: 0.9775    \n",
      "Epoch 2/12\n",
      "8149/8149 [==============================] - 10s - loss: 0.0371 - acc: 0.9869    \n",
      "Epoch 3/12\n",
      "8149/8149 [==============================] - 10s - loss: 0.0327 - acc: 0.9883    \n",
      "Epoch 4/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.0316 - acc: 0.9880    \n",
      "Epoch 5/12\n",
      "8149/8149 [==============================] - 11s - loss: 0.0270 - acc: 0.9904    \n",
      "Epoch 6/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.0251 - acc: 0.9913    \n",
      "Epoch 7/12\n",
      "8149/8149 [==============================] - 8s - loss: 0.0241 - acc: 0.9918     \n",
      "Epoch 8/12\n",
      "8149/8149 [==============================] - 9s - loss: 0.0217 - acc: 0.9924     \n",
      "Epoch 9/12\n",
      "8149/8149 [==============================] - 9s - loss: 0.0215 - acc: 0.9926     \n",
      "Epoch 10/12\n",
      "8149/8149 [==============================] - 7s - loss: 0.0208 - acc: 0.9929     \n",
      "Epoch 11/12\n",
      "8149/8149 [==============================] - 8s - loss: 0.0193 - acc: 0.9935     \n",
      "Epoch 12/12\n",
      "8149/8149 [==============================] - 8s - loss: 0.0179 - acc: 0.9945     \n",
      "4074/4074 [==============================] - 3s     \n",
      "8056/8149 [============================>.] - ETA: 0sEpoch 1/12\n",
      "8149/8149 [==============================] - 9s - loss: 0.0618 - acc: 0.9799     \n",
      "Epoch 2/12\n",
      "8149/8149 [==============================] - 8s - loss: 0.0424 - acc: 0.9869     \n",
      "Epoch 3/12\n",
      "8149/8149 [==============================] - 8s - loss: 0.0386 - acc: 0.9874     \n",
      "Epoch 4/12\n",
      "8149/8149 [==============================] - 8s - loss: 0.0338 - acc: 0.9904     \n",
      "Epoch 5/12\n",
      "8149/8149 [==============================] - 8s - loss: 0.0332 - acc: 0.9899     \n",
      "Epoch 6/12\n",
      "8149/8149 [==============================] - 9s - loss: 0.0305 - acc: 0.9898     \n",
      "Epoch 7/12\n",
      "8149/8149 [==============================] - 8s - loss: 0.0282 - acc: 0.9910     \n",
      "Epoch 8/12\n",
      "8149/8149 [==============================] - 8s - loss: 0.0274 - acc: 0.9913     \n",
      "Epoch 9/12\n",
      "8149/8149 [==============================] - 8s - loss: 0.0256 - acc: 0.9921     \n",
      "Epoch 10/12\n",
      "8149/8149 [==============================] - 8s - loss: 0.0241 - acc: 0.9933     \n",
      "Epoch 11/12\n",
      "8149/8149 [==============================] - 8s - loss: 0.0218 - acc: 0.9940     \n",
      "Epoch 12/12\n",
      "8149/8149 [==============================] - 8s - loss: 0.0232 - acc: 0.9934     \n",
      "8149/8149 [==============================] - 4s     \n",
      "Epoch 1/4\n",
      "8148/8148 [==============================] - 15s - loss: 0.6931 - acc: 0.5114    \n",
      "Epoch 2/4\n",
      "8148/8148 [==============================] - 13s - loss: 0.6912 - acc: 0.5206    \n",
      "Epoch 3/4\n",
      "8148/8148 [==============================] - 13s - loss: 0.6733 - acc: 0.5968    \n",
      "Epoch 4/4\n",
      "8148/8148 [==============================] - 14s - loss: 0.6075 - acc: 0.7739    \n",
      "8064/8148 [============================>.] - ETA: 0sEpoch 1/4\n",
      "8149/8149 [==============================] - 15s - loss: 0.6927 - acc: 0.5129    \n",
      "Epoch 2/4\n",
      "8149/8149 [==============================] - 13s - loss: 0.6859 - acc: 0.5645    \n",
      "Epoch 3/4\n",
      "8149/8149 [==============================] - 13s - loss: 0.6259 - acc: 0.7124    \n",
      "Epoch 4/4\n",
      "8149/8149 [==============================] - 13s - loss: 0.5040 - acc: 0.7732    \n",
      "8064/8149 [============================>.] - ETA: 0sEpoch 1/4\n",
      "8149/8149 [==============================] - 15s - loss: 0.6931 - acc: 0.5112    \n",
      "Epoch 2/4\n",
      "8149/8149 [==============================] - 16s - loss: 0.6914 - acc: 0.5272    \n",
      "Epoch 3/4\n",
      "8149/8149 [==============================] - 14s - loss: 0.6770 - acc: 0.6478    \n",
      "Epoch 4/4\n",
      "8149/8149 [==============================] - 15s - loss: 0.6134 - acc: 0.7373    \n",
      "4074/4074 [==============================] - 2s     \n",
      "8149/8149 [==============================] - 3s     \n",
      "Epoch 1/8\n",
      "8148/8148 [==============================] - 5s - loss: 0.5826 - acc: 0.6399     \n",
      "Epoch 2/8\n",
      "8148/8148 [==============================] - 4s - loss: 0.0984 - acc: 0.9683     \n",
      "Epoch 3/8\n",
      "8148/8148 [==============================] - 4s - loss: 0.0698 - acc: 0.9772     \n",
      "Epoch 4/8\n",
      "8148/8148 [==============================] - 4s - loss: 0.0625 - acc: 0.9788     \n",
      "Epoch 5/8\n",
      "8148/8148 [==============================] - 4s - loss: 0.0538 - acc: 0.9828     \n",
      "Epoch 6/8\n",
      "8148/8148 [==============================] - 4s - loss: 0.0499 - acc: 0.9837     \n",
      "Epoch 7/8\n",
      "8148/8148 [==============================] - 4s - loss: 0.0476 - acc: 0.9840     \n",
      "Epoch 8/8\n",
      "8148/8148 [==============================] - 4s - loss: 0.0443 - acc: 0.9861     \n",
      "8064/8148 [============================>.] - ETA: 0sEpoch 1/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.5931 - acc: 0.6273     \n",
      "Epoch 2/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0981 - acc: 0.9720     \n",
      "Epoch 3/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.0674 - acc: 0.9778     \n",
      "Epoch 4/8\n",
      "8149/8149 [==============================] - 8s - loss: 0.0560 - acc: 0.9844     \n",
      "Epoch 5/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0500 - acc: 0.9836     \n",
      "Epoch 6/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0437 - acc: 0.9858     \n",
      "Epoch 7/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0389 - acc: 0.9872     \n",
      "Epoch 8/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0380 - acc: 0.9883     \n",
      "8096/8149 [============================>.] - ETA: 0sEpoch 1/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.6961 - acc: 0.5126     \n",
      "Epoch 2/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.2205 - acc: 0.9215     \n",
      "Epoch 3/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0792 - acc: 0.9764     \n",
      "Epoch 4/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0637 - acc: 0.9794     \n",
      "Epoch 5/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0564 - acc: 0.9829     \n",
      "Epoch 6/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0516 - acc: 0.9837     \n",
      "Epoch 7/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0487 - acc: 0.9855     \n",
      "Epoch 8/8\n",
      "8149/8149 [==============================] - 4s - loss: 0.0468 - acc: 0.9848     \n",
      "8032/8149 [============================>.] - ETA: 0sEpoch 1/4\n",
      "8148/8148 [==============================] - 15s - loss: 0.3696 - acc: 0.8927    \n",
      "Epoch 2/4\n",
      "8148/8148 [==============================] - 13s - loss: 0.1383 - acc: 0.9770    \n",
      "Epoch 3/4\n",
      "8148/8148 [==============================] - 13s - loss: 0.0962 - acc: 0.9794    \n",
      "Epoch 4/4\n",
      "8148/8148 [==============================] - 14s - loss: 0.0813 - acc: 0.9812    \n",
      "8064/8148 [============================>.] - ETA: 0sEpoch 1/4\n",
      "8149/8149 [==============================] - 15s - loss: 0.5159 - acc: 0.8359    \n",
      "Epoch 2/4\n",
      "8149/8149 [==============================] - 13s - loss: 0.1960 - acc: 0.9821    \n",
      "Epoch 3/4\n",
      "8149/8149 [==============================] - 13s - loss: 0.1150 - acc: 0.9845    \n",
      "Epoch 4/4\n",
      "8149/8149 [==============================] - 13s - loss: 0.0823 - acc: 0.9869    \n",
      "8128/8149 [============================>.] - ETA: 0sEpoch 1/4\n",
      "8149/8149 [==============================] - 18s - loss: 0.6931 - acc: 0.5089    \n",
      "Epoch 2/4\n",
      "8149/8149 [==============================] - 15s - loss: 0.3102 - acc: 0.9378    \n",
      "Epoch 3/4\n",
      "8149/8149 [==============================] - 18s - loss: 0.1294 - acc: 0.9780    \n",
      "Epoch 4/4\n",
      "8149/8149 [==============================] - 15s - loss: 0.0830 - acc: 0.9854    \n",
      "4074/4074 [==============================] - 3s     \n",
      "8064/8149 [============================>.] - ETA: 0sEpoch 1/12\n",
      "8148/8148 [==============================] - 11s - loss: 0.2151 - acc: 0.8906    \n",
      "Epoch 2/12\n",
      "8148/8148 [==============================] - 10s - loss: 0.0529 - acc: 0.9815    \n",
      "Epoch 3/12\n",
      "8148/8148 [==============================] - 9s - loss: 0.0446 - acc: 0.9850     \n",
      "Epoch 4/12\n",
      "8148/8148 [==============================] - 10s - loss: 0.0331 - acc: 0.9892    \n",
      "Epoch 5/12\n",
      "8148/8148 [==============================] - 9s - loss: 0.0308 - acc: 0.9907     \n",
      "Epoch 6/12\n",
      "8148/8148 [==============================] - 9s - loss: 0.0261 - acc: 0.9919     \n",
      "Epoch 7/12\n",
      "8148/8148 [==============================] - 9s - loss: 0.0212 - acc: 0.9932     \n",
      "Epoch 8/12\n",
      "8148/8148 [==============================] - 9s - loss: 0.0187 - acc: 0.9946     \n",
      "Epoch 9/12\n",
      "8148/8148 [==============================] - 9s - loss: 0.0165 - acc: 0.9944     \n",
      "Epoch 10/12\n",
      "8148/8148 [==============================] - 9s - loss: 0.0151 - acc: 0.9955     \n",
      "Epoch 11/12\n",
      "8148/8148 [==============================] - 9s - loss: 0.0129 - acc: 0.9958     \n",
      "Epoch 12/12\n",
      "8148/8148 [==============================] - 9s - loss: 0.0111 - acc: 0.9966     \n",
      "8096/8148 [============================>.] - ETA: 0sEpoch 1/12\n",
      "8149/8149 [==============================] - 11s - loss: 0.2485 - acc: 0.8578    \n",
      "Epoch 2/12\n",
      "8149/8149 [==============================] - 10s - loss: 0.0523 - acc: 0.9816    \n",
      "Epoch 3/12\n",
      "8149/8149 [==============================] - 9s - loss: 0.0402 - acc: 0.9859     \n",
      "Epoch 4/12\n",
      "8149/8149 [==============================] - 9s - loss: 0.0324 - acc: 0.9887     \n",
      "Epoch 5/12\n",
      "8149/8149 [==============================] - 9s - loss: 0.0282 - acc: 0.9907     \n",
      "Epoch 6/12\n",
      "8149/8149 [==============================] - 10s - loss: 0.0219 - acc: 0.9926    \n",
      "Epoch 7/12\n",
      "8149/8149 [==============================] - 9s - loss: 0.0197 - acc: 0.9931     \n",
      "Epoch 8/12\n",
      "8149/8149 [==============================] - 10s - loss: 0.0168 - acc: 0.9946    \n",
      "Epoch 9/12\n",
      "8149/8149 [==============================] - 9s - loss: 0.0147 - acc: 0.9956     \n",
      "Epoch 10/12\n",
      "8149/8149 [==============================] - 9s - loss: 0.0136 - acc: 0.9956     \n",
      "Epoch 11/12\n",
      "8149/8149 [==============================] - 9s - loss: 0.0113 - acc: 0.9956     \n",
      "Epoch 12/12\n",
      "8149/8149 [==============================] - 9s - loss: 0.0126 - acc: 0.9964     \n",
      "8104/8149 [============================>.] - ETA: 0sEpoch 1/12\n",
      "8149/8149 [==============================] - 11s - loss: 0.2643 - acc: 0.8475    \n",
      "Epoch 2/12\n",
      "8149/8149 [==============================] - 10s - loss: 0.0528 - acc: 0.9836    \n",
      "Epoch 3/12\n",
      "8149/8149 [==============================] - 10s - loss: 0.0432 - acc: 0.9860    \n",
      "Epoch 4/12\n",
      "8149/8149 [==============================] - 10s - loss: 0.0372 - acc: 0.9898    \n",
      "Epoch 5/12\n",
      "8149/8149 [==============================] - 10s - loss: 0.0320 - acc: 0.9901    \n",
      "Epoch 6/12\n",
      "8149/8149 [==============================] - 11s - loss: 0.0271 - acc: 0.9919    \n",
      "Epoch 7/12\n",
      "8149/8149 [==============================] - 10s - loss: 0.0219 - acc: 0.9926    \n",
      "Epoch 8/12\n",
      "8149/8149 [==============================] - 10s - loss: 0.0209 - acc: 0.9937    \n",
      "Epoch 9/12\n",
      "8149/8149 [==============================] - 10s - loss: 0.0182 - acc: 0.9941    \n",
      "Epoch 10/12\n",
      "8149/8149 [==============================] - 10s - loss: 0.0177 - acc: 0.9950    \n",
      "Epoch 11/12\n",
      "8149/8149 [==============================] - 10s - loss: 0.0152 - acc: 0.9955    \n",
      "Epoch 12/12\n",
      "8149/8149 [==============================] - 10s - loss: 0.0138 - acc: 0.9960    \n",
      "8088/8149 [============================>.] - ETA: 0sEpoch 1/8\n",
      "8148/8148 [==============================] - 8s - loss: 0.1916 - acc: 0.9432     \n",
      "Epoch 2/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8148/8148 [==============================] - 5s - loss: 0.0775 - acc: 0.9764     \n",
      "Epoch 3/8\n",
      "8148/8148 [==============================] - 5s - loss: 0.0649 - acc: 0.9772     \n",
      "Epoch 4/8\n",
      "8148/8148 [==============================] - ETA: 0s - loss: 0.0612 - acc: 0.979 - 5s - loss: 0.0614 - acc: 0.9799     \n",
      "Epoch 5/8\n",
      "8148/8148 [==============================] - 5s - loss: 0.0570 - acc: 0.9812     \n",
      "Epoch 6/8\n",
      "8148/8148 [==============================] - 5s - loss: 0.0542 - acc: 0.9816     \n",
      "Epoch 7/8\n",
      "8148/8148 [==============================] - 5s - loss: 0.0493 - acc: 0.9832     \n",
      "Epoch 8/8\n",
      "8148/8148 [==============================] - 5s - loss: 0.0491 - acc: 0.9840     \n",
      "8096/8148 [============================>.] - ETA: 0sEpoch 1/8\n",
      "8149/8149 [==============================] - 7s - loss: 0.2244 - acc: 0.9232     \n",
      "Epoch 2/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.0824 - acc: 0.9708     \n",
      "Epoch 3/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.0672 - acc: 0.9748     \n",
      "Epoch 4/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.0573 - acc: 0.9788     \n",
      "Epoch 5/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.0546 - acc: 0.9812     \n",
      "Epoch 6/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.0505 - acc: 0.9821     \n",
      "Epoch 7/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.0462 - acc: 0.9842     \n",
      "Epoch 8/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.0454 - acc: 0.9840     \n",
      "8096/8149 [============================>.] - ETA: 0sEpoch 1/8\n",
      "8149/8149 [==============================] - 7s - loss: 0.2222 - acc: 0.9254     \n",
      "Epoch 2/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.0816 - acc: 0.9725     \n",
      "Epoch 3/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.0667 - acc: 0.9771     \n",
      "Epoch 4/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.0611 - acc: 0.9793     \n",
      "Epoch 5/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.0547 - acc: 0.9833     \n",
      "Epoch 6/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.0534 - acc: 0.9834     \n",
      "Epoch 7/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.0521 - acc: 0.9842     \n",
      "Epoch 8/8\n",
      "8149/8149 [==============================] - 5s - loss: 0.0507 - acc: 0.9840     \n",
      "8144/8149 [============================>.] - ETA: 0sEpoch 1/4\n",
      "8148/8148 [==============================] - 5s - loss: 0.0659 - acc: 0.9785     - ETA: 1s - loss: 0\n",
      "Epoch 2/4\n",
      "8148/8148 [==============================] - 4s - loss: 0.0282 - acc: 0.9898     \n",
      "Epoch 3/4\n",
      "8148/8148 [==============================] - 4s - loss: 0.0180 - acc: 0.9940     \n",
      "Epoch 4/4\n",
      "8148/8148 [==============================] - 4s - loss: 0.0171 - acc: 0.9944     \n",
      "8000/8148 [============================>.] - ETA: 0sEpoch 1/4\n",
      "8149/8149 [==============================] - 6s - loss: 0.0499 - acc: 0.9806     \n",
      "Epoch 2/4\n",
      "8149/8149 [==============================] - 4s - loss: 0.0188 - acc: 0.9941     \n",
      "Epoch 3/4\n",
      "8149/8149 [==============================] - 4s - loss: 0.0186 - acc: 0.9937     \n",
      "Epoch 4/4\n",
      "8149/8149 [==============================] - 4s - loss: 0.0137 - acc: 0.9951     \n",
      "7936/8149 [============================>.] - ETA: 0sEpoch 1/4\n",
      "8149/8149 [==============================] - 5s - loss: 0.0749 - acc: 0.9728     \n",
      "Epoch 2/4\n",
      "8149/8149 [==============================] - 4s - loss: 0.0208 - acc: 0.9929     \n",
      "Epoch 3/4\n",
      "8149/8149 [==============================] - 3s - loss: 0.0150 - acc: 0.9961     \n",
      "Epoch 4/4\n",
      "8149/8149 [==============================] - 3s - loss: 0.0140 - acc: 0.9951     \n",
      "8000/8149 [============================>.] - ETA: 0sEpoch 1/12\n",
      "8148/8148 [==============================] - 15s - loss: 0.5941 - acc: 0.6003    \n",
      "Epoch 2/12\n",
      "8148/8148 [==============================] - 13s - loss: 0.3696 - acc: 0.8357    \n",
      "Epoch 3/12\n",
      "8148/8148 [==============================] - 13s - loss: 0.3095 - acc: 0.8554    \n",
      "Epoch 4/12\n",
      "8148/8148 [==============================] - 13s - loss: 0.2768 - acc: 0.8538    \n",
      "Epoch 5/12\n",
      "8148/8148 [==============================] - 13s - loss: 0.2615 - acc: 0.8504    \n",
      "Epoch 6/12\n",
      "8148/8148 [==============================] - 13s - loss: 0.2415 - acc: 0.8601    \n",
      "Epoch 7/12\n",
      "8148/8148 [==============================] - 13s - loss: 0.2400 - acc: 0.8558    \n",
      "Epoch 8/12\n",
      "8148/8148 [==============================] - 13s - loss: 0.2336 - acc: 0.8627    \n",
      "Epoch 9/12\n",
      "8148/8148 [==============================] - 13s - loss: 0.2196 - acc: 0.8816    \n",
      "Epoch 10/12\n",
      "8148/8148 [==============================] - 13s - loss: 0.2173 - acc: 0.9147    \n",
      "Epoch 11/12\n",
      "8148/8148 [==============================] - 13s - loss: 0.1982 - acc: 0.9215    \n",
      "Epoch 12/12\n",
      "8148/8148 [==============================] - 13s - loss: 0.1910 - acc: 0.9245    \n",
      "4075/4075 [==============================] - 2s     \n",
      "8064/8148 [============================>.] - ETA: 0sEpoch 1/12\n",
      "8149/8149 [==============================] - 15s - loss: 0.6019 - acc: 0.6499    \n",
      "Epoch 2/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.4229 - acc: 0.7730    \n",
      "Epoch 3/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.3789 - acc: 0.8450    \n",
      "Epoch 4/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.3528 - acc: 0.8568    \n",
      "Epoch 5/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.3324 - acc: 0.8597    \n",
      "Epoch 6/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.3249 - acc: 0.8617    \n",
      "Epoch 7/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.3073 - acc: 0.8720    \n",
      "Epoch 8/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.2973 - acc: 0.8723    \n",
      "Epoch 9/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.2858 - acc: 0.8745    \n",
      "Epoch 10/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.2889 - acc: 0.8688    \n",
      "Epoch 11/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.2856 - acc: 0.8683    \n",
      "Epoch 12/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.2526 - acc: 0.8697    \n",
      "4074/4074 [==============================] - 2s     \n",
      "8064/8149 [============================>.] - ETA: 0sEpoch 1/12\n",
      "8149/8149 [==============================] - 15s - loss: 0.6017 - acc: 0.6418    \n",
      "Epoch 2/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.3493 - acc: 0.8362    \n",
      "Epoch 3/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.2924 - acc: 0.8540    \n",
      "Epoch 4/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.2765 - acc: 0.8552    \n",
      "Epoch 5/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.2683 - acc: 0.8440    \n",
      "Epoch 6/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.2503 - acc: 0.8524    \n",
      "Epoch 7/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.2485 - acc: 0.8520    \n",
      "Epoch 8/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.2416 - acc: 0.8498    \n",
      "Epoch 9/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.2344 - acc: 0.8586    \n",
      "Epoch 10/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.2285 - acc: 0.8660    \n",
      "Epoch 11/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.2354 - acc: 0.8617    \n",
      "Epoch 12/12\n",
      "8149/8149 [==============================] - 13s - loss: 0.2199 - acc: 0.8610    \n",
      "8064/8149 [============================>.] - ETA: 0sEpoch 1/4\n",
      "8148/8148 [==============================] - 7s - loss: 0.0935 - acc: 0.9655     \n",
      "Epoch 2/4\n",
      "8148/8148 [==============================] - 5s - loss: 0.0623 - acc: 0.9780     \n",
      "Epoch 3/4\n",
      "8148/8148 [==============================] - 5s - loss: 0.0479 - acc: 0.9851     \n",
      "Epoch 4/4\n",
      "8148/8148 [==============================] - 5s - loss: 0.0443 - acc: 0.9832     \n",
      "8080/8148 [============================>.] - ETA: 0sEpoch 1/4\n",
      "8149/8149 [==============================] - 7s - loss: 0.1053 - acc: 0.9634     \n",
      "Epoch 2/4\n",
      "8149/8149 [==============================] - 5s - loss: 0.0584 - acc: 0.9806     \n",
      "Epoch 3/4\n",
      "8149/8149 [==============================] - 5s - loss: 0.0596 - acc: 0.9836     \n",
      "Epoch 4/4\n",
      "8149/8149 [==============================] - 5s - loss: 0.0445 - acc: 0.9854     \n",
      "8112/8149 [============================>.] - ETA: 0sEpoch 1/4\n",
      "8149/8149 [==============================] - 7s - loss: 0.1053 - acc: 0.9623     \n",
      "Epoch 2/4\n",
      "8149/8149 [==============================] - 5s - loss: 0.0655 - acc: 0.9762     \n",
      "Epoch 3/4\n",
      "8149/8149 [==============================] - 5s - loss: 0.0623 - acc: 0.9786     \n",
      "Epoch 4/4\n",
      "8149/8149 [==============================] - 5s - loss: 0.0462 - acc: 0.9840     \n",
      "8064/8149 [============================>.] - ETA: 0sEpoch 1/12\n",
      "8148/8148 [==============================] - 9s - loss: 0.1034 - acc: 0.9642     \n",
      "Epoch 2/12\n",
      "8148/8148 [==============================] - 5s - loss: 0.0536 - acc: 0.9842     \n",
      "Epoch 3/12\n",
      "8148/8148 [==============================] - 4s - loss: 0.0458 - acc: 0.9856     \n",
      "Epoch 4/12\n",
      "8148/8148 [==============================] - 5s - loss: 0.0409 - acc: 0.9882     \n",
      "Epoch 5/12\n",
      "8148/8148 [==============================] - 4s - loss: 0.0356 - acc: 0.9890     \n",
      "Epoch 6/12\n",
      "8148/8148 [==============================] - 4s - loss: 0.0315 - acc: 0.9913     \n",
      "Epoch 7/12\n",
      "8148/8148 [==============================] - 6s - loss: 0.0301 - acc: 0.9917     \n",
      "Epoch 8/12\n",
      "8148/8148 [==============================] - 6s - loss: 0.0282 - acc: 0.9910     \n",
      "Epoch 9/12\n",
      "8148/8148 [==============================] - 5s - loss: 0.0244 - acc: 0.9920     \n",
      "Epoch 10/12\n",
      "8148/8148 [==============================] - 4s - loss: 0.0238 - acc: 0.9930     \n",
      "Epoch 11/12\n",
      "8148/8148 [==============================] - 4s - loss: 0.0212 - acc: 0.9940     \n",
      "Epoch 12/12\n",
      "8148/8148 [==============================] - 4s - loss: 0.0233 - acc: 0.9931     \n",
      "7936/8148 [============================>.] - ETA: 0sEpoch 1/12\n",
      "8149/8149 [==============================] - 6s - loss: 0.1085 - acc: 0.9616     \n",
      "Epoch 2/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0457 - acc: 0.9856     \n",
      "Epoch 3/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0406 - acc: 0.9877     \n",
      "Epoch 4/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0344 - acc: 0.9904     \n",
      "Epoch 5/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0325 - acc: 0.9907     - ETA:\n",
      "Epoch 6/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0285 - acc: 0.9898     \n",
      "Epoch 7/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0254 - acc: 0.9912     \n",
      "Epoch 8/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0248 - acc: 0.9913     - ETA: \n",
      "Epoch 9/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0226 - acc: 0.9929     \n",
      "Epoch 10/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0194 - acc: 0.9945     \n",
      "Epoch 11/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0175 - acc: 0.9951     \n",
      "Epoch 12/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0172 - acc: 0.9934     \n",
      "8000/8149 [============================>.] - ETA: 0sEpoch 1/12\n",
      "8149/8149 [==============================] - 6s - loss: 0.0786 - acc: 0.9709     \n",
      "Epoch 2/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0348 - acc: 0.9890     \n",
      "Epoch 3/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0277 - acc: 0.9904     \n",
      "Epoch 4/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0260 - acc: 0.9920     \n",
      "Epoch 5/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0222 - acc: 0.9926     \n",
      "Epoch 6/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0200 - acc: 0.9940     \n",
      "Epoch 7/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0165 - acc: 0.9958     \n",
      "Epoch 8/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0172 - acc: 0.9947     \n",
      "Epoch 9/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0140 - acc: 0.9958     \n",
      "Epoch 10/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0172 - acc: 0.9944     \n",
      "Epoch 11/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0139 - acc: 0.9960     \n",
      "Epoch 12/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0138 - acc: 0.9958     \n",
      "8000/8149 [============================>.] - ETA: 0sEpoch 1/12\n",
      "8148/8148 [==============================] - 6s - loss: 0.6953 - acc: 0.5068     \n",
      "Epoch 2/12\n",
      "8148/8148 [==============================] - 4s - loss: 0.5013 - acc: 0.7893     \n",
      "Epoch 3/12\n",
      "8148/8148 [==============================] - 4s - loss: 0.1624 - acc: 0.9618     \n",
      "Epoch 4/12\n",
      "8148/8148 [==============================] - 4s - loss: 0.1166 - acc: 0.9683     \n",
      "Epoch 5/12\n",
      "8148/8148 [==============================] - 4s - loss: 0.0959 - acc: 0.9725     - ETA: 1s - \n",
      "Epoch 6/12\n",
      "8148/8148 [==============================] - 4s - loss: 0.0835 - acc: 0.9748     \n",
      "Epoch 7/12\n",
      "8148/8148 [==============================] - 4s - loss: 0.0748 - acc: 0.9784     - ETA: 0s - loss: 0.0782\n",
      "Epoch 8/12\n",
      "8148/8148 [==============================] - 4s - loss: 0.0710 - acc: 0.9788     \n",
      "Epoch 9/12\n",
      "8148/8148 [==============================] - 4s - loss: 0.0639 - acc: 0.9809     \n",
      "Epoch 10/12\n",
      "8148/8148 [==============================] - 4s - loss: 0.0604 - acc: 0.9807     \n",
      "Epoch 11/12\n",
      "8148/8148 [==============================] - 4s - loss: 0.0542 - acc: 0.9821     \n",
      "Epoch 12/12\n",
      "8148/8148 [==============================] - 4s - loss: 0.0524 - acc: 0.9836     \n",
      "8064/8148 [============================>.] - ETA: 0sEpoch 1/12\n",
      "8149/8149 [==============================] - 6s - loss: 0.6642 - acc: 0.5817     \n",
      "Epoch 2/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.1293 - acc: 0.9683     \n",
      "Epoch 3/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0738 - acc: 0.9807     \n",
      "Epoch 4/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0623 - acc: 0.9826     \n",
      "Epoch 5/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0536 - acc: 0.9849     \n",
      "Epoch 6/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0489 - acc: 0.9847     \n",
      "Epoch 7/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0438 - acc: 0.9871     \n",
      "Epoch 8/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0416 - acc: 0.9875     \n",
      "Epoch 9/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0359 - acc: 0.9892     \n",
      "Epoch 10/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0350 - acc: 0.9896     \n",
      "Epoch 11/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0346 - acc: 0.9891     \n",
      "Epoch 12/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0298 - acc: 0.9915     \n",
      "8149/8149 [==============================] - 1s     \n",
      "Epoch 1/12\n",
      "8149/8149 [==============================] - 6s - loss: 0.6309 - acc: 0.6359     \n",
      "Epoch 2/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.1535 - acc: 0.9664     \n",
      "Epoch 3/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0978 - acc: 0.9735     - ETA: 1s - loss\n",
      "Epoch 4/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0801 - acc: 0.9784     \n",
      "Epoch 5/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0693 - acc: 0.9820     - ETA: 1s -\n",
      "Epoch 6/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0637 - acc: 0.9829     \n",
      "Epoch 7/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0580 - acc: 0.9840     \n",
      "Epoch 8/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0546 - acc: 0.9843     \n",
      "Epoch 9/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0494 - acc: 0.9860     \n",
      "Epoch 10/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0460 - acc: 0.9859     \n",
      "Epoch 11/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0447 - acc: 0.9875     \n",
      "Epoch 12/12\n",
      "8149/8149 [==============================] - 4s - loss: 0.0430 - acc: 0.9865     \n",
      "8149/8149 [==============================] - 1s     \n",
      "Epoch 1/4\n",
      "8148/8148 [==============================] - 16s - loss: 0.6933 - acc: 0.5021    \n",
      "Epoch 2/4\n",
      "8148/8148 [==============================] - 14s - loss: 0.6939 - acc: 0.5007    \n",
      "Epoch 3/4\n",
      "8148/8148 [==============================] - 14s - loss: 0.6932 - acc: 0.5061    \n",
      "Epoch 4/4\n",
      "8148/8148 [==============================] - 14s - loss: 0.6935 - acc: 0.5041    \n",
      "8064/8148 [============================>.] - ETA: 0sEpoch 1/4\n",
      "8149/8149 [==============================] - 16s - loss: 0.6929 - acc: 0.5143    \n",
      "Epoch 2/4\n",
      "8149/8149 [==============================] - 14s - loss: 0.6928 - acc: 0.5183    \n",
      "Epoch 3/4\n",
      "8149/8149 [==============================] - 14s - loss: 0.6925 - acc: 0.5169    \n",
      "Epoch 4/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8149/8149 [==============================] - 16s - loss: 0.6932 - acc: 0.5125    \n",
      "8064/8149 [============================>.] - ETA: 0sEpoch 1/4\n",
      "8149/8149 [==============================] - 17s - loss: 0.6946 - acc: 0.4948    \n",
      "Epoch 2/4\n",
      "8149/8149 [==============================] - 13s - loss: 0.6943 - acc: 0.4960    \n",
      "Epoch 3/4\n",
      "8149/8149 [==============================] - 13s - loss: 0.6947 - acc: 0.4901    \n",
      "Epoch 4/4\n",
      "8149/8149 [==============================] - 13s - loss: 0.6944 - acc: 0.4938    \n",
      "8064/8149 [============================>.] - ETA: 0sEpoch 1/12\n",
      "12223/12223 [==============================] - 8s - loss: 0.0933 - acc: 0.9689     \n",
      "Epoch 2/12\n",
      "12223/12223 [==============================] - 6s - loss: 0.0447 - acc: 0.9869     \n",
      "Epoch 3/12\n",
      "12223/12223 [==============================] - 6s - loss: 0.0341 - acc: 0.9895     \n",
      "Epoch 4/12\n",
      "12223/12223 [==============================] - 7s - loss: 0.0287 - acc: 0.9911     \n",
      "Epoch 5/12\n",
      "12223/12223 [==============================] - 8s - loss: 0.0246 - acc: 0.9925     \n",
      "Epoch 6/12\n",
      "12223/12223 [==============================] - 7s - loss: 0.0204 - acc: 0.9939     \n",
      "Epoch 7/12\n",
      "12223/12223 [==============================] - 6s - loss: 0.0190 - acc: 0.9951     \n",
      "Epoch 8/12\n",
      "12223/12223 [==============================] - 6s - loss: 0.0176 - acc: 0.9948     \n",
      "Epoch 9/12\n",
      "12223/12223 [==============================] - 6s - loss: 0.0175 - acc: 0.9944     \n",
      "Epoch 10/12\n",
      "12223/12223 [==============================] - 6s - loss: 0.0165 - acc: 0.9956     \n",
      "Epoch 11/12\n",
      "12223/12223 [==============================] - 6s - loss: 0.0149 - acc: 0.9961     \n",
      "Epoch 12/12\n",
      "12223/12223 [==============================] - 6s - loss: 0.0142 - acc: 0.9961     \n"
     ]
    }
   ],
   "source": [
    "# Lists of possible Values for Hyperparameters\n",
    "batch_size = [8, 16, 32, 64, 128]\n",
    "_optimizer = ['Adam', 'SGD', 'Adamax', 'Nadam']\n",
    "learning_rate = [.001, .002, .005, .01]\n",
    "epochs = [4, 8, 12]\n",
    "activator = ['softmax', 'relu', 'tanh', 'sigmoid', 'linear']\n",
    "dropout_rate1 = [.0, .1, .25]\n",
    "dropout_rate2 = [.0, .1, .25, .5]\n",
    "neurons = [8, 16, 32]\n",
    "param_grid = dict(activator=activator, dropout_rate1=dropout_rate1, dropout_rate2=dropout_rate2,\n",
    "                  _optimizer=_optimizer, batch_size=batch_size, epochs=epochs, neurons=neurons, \n",
    "                  learning_rate=learning_rate)\n",
    "search_model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "# I chose to tune all of the parameters together, because there is interdependency.\n",
    "# Because of this, I also chose to do a random search to reduce the expense.\n",
    "grid = RandomizedSearchCV(estimator=search_model, param_distributions=param_grid, random_state=3, n_jobs=1, n_iter=20)\n",
    "grid_result = grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99443671752688123"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the very best the result?\n",
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1984/2060 [===========================>..] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99126213592233015"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure you don't have overfitting by checking against the test set\n",
    "grid_result.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_optimizer': 'Adamax',\n",
       " 'activator': 'relu',\n",
       " 'batch_size': 64,\n",
       " 'dropout_rate1': 0.25,\n",
       " 'dropout_rate2': 0.1,\n",
       " 'epochs': 12,\n",
       " 'learning_rate': 0.005,\n",
       " 'neurons': 8}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the final parameters\n",
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" >\n",
       "                    <source src=\"https://www.dropbox.com/s/pdtsa6gs9uhqo4j/Star%20Wars%20V%20-%20The%20Imperial%20March%20%28Darth%20Vader%27s%20Theme%29.mp3?dl=0\" type=\"None\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To let you know that the 1.5 hour job is complete\n",
    "from IPython.display import Audio\n",
    "Audio(filename='./JobDone.mp3', autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([  35.42122801,  180.54069916,  208.0674359 ,   28.82937503,\n",
       "          32.49717347,   37.71703704,  216.42127911,   19.9575278 ,\n",
       "         113.43821383,   59.78622007,   38.95401669,   62.60841735,\n",
       "         123.44176221,   47.89012225,   19.32160266,  162.77963122,\n",
       "          24.54693659,   58.32220109,   54.70594843,   60.1191566 ]),\n",
       " 'mean_score_time': array([ 1.55711532,  2.40351176,  3.04836106,  1.52377597,  2.78812178,\n",
       "         1.78898096,  3.88805199,  1.867546  ,  3.28094538,  2.69291186,\n",
       "         2.07740641,  2.76209879,  3.94490997,  2.70156272,  2.10820707,\n",
       "         2.78730138,  2.8044219 ,  2.35423303,  2.44961476,  3.43155909]),\n",
       " 'mean_test_score': array([ 0.99190052,  0.98985519,  0.51255829,  0.99329134,  0.98625542,\n",
       "         0.99190052,  0.51255829,  0.51255829,  0.99050969,  0.95246666,\n",
       "         0.98429191,  0.98641905,  0.99337315,  0.9836374 ,  0.99361859,\n",
       "         0.98699174,  0.989937  ,  0.99443672,  0.98830074,  0.50274074]),\n",
       " 'mean_train_score': array([ 0.9966865 ,  0.99337313,  0.51255812,  0.99779098,  0.98891428,\n",
       "         0.99660468,  0.51255812,  0.51255812,  0.99541844,  0.94927637,\n",
       "         0.98670531,  0.98907786,  0.99783195,  0.9852736 ,  0.99791376,\n",
       "         0.99079607,  0.99267784,  0.99693196,  0.99063234,  0.50490892]),\n",
       " 'param__optimizer': masked_array(data = ['Adam' 'Adam' 'SGD' 'Adamax' 'Nadam' 'Adamax' 'SGD' 'SGD' 'Adamax'\n",
       "  'Adamax' 'Nadam' 'Adam' 'Adam' 'SGD' 'Adam' 'Nadam' 'Adam' 'Adamax' 'Adam'\n",
       "  'SGD'],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_activator': masked_array(data = ['tanh' 'softmax' 'softmax' 'relu' 'sigmoid' 'relu' 'softmax' 'sigmoid'\n",
       "  'linear' 'softmax' 'sigmoid' 'softmax' 'sigmoid' 'linear' 'relu' 'softmax'\n",
       "  'relu' 'relu' 'sigmoid' 'softmax'],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_batch_size': masked_array(data = [64 64 16 128 8 64 16 128 8 128 32 64 8 16 64 128 16 64 64 128],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_dropout_rate1': masked_array(data = [0.25 0.25 0.1 0.0 0.25 0.25 0.0 0.0 0.1 0.1 0.0 0.1 0.0 0.0 0.1 0.0 0.0\n",
       "  0.25 0.25 0.25],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_dropout_rate2': masked_array(data = [0.25 0.25 0.5 0.1 0.0 0.0 0.0 0.25 0.0 0.25 0.25 0.0 0.1 0.25 0.0 0.5 0.5\n",
       "  0.1 0.1 0.5],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_epochs': masked_array(data = [8 12 12 8 4 8 12 4 12 4 8 4 12 8 4 12 4 12 12 4],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_learning_rate': masked_array(data = [0.005 0.005 0.002 0.005 0.001 0.01 0.002 0.01 0.001 0.001 0.001 0.005\n",
       "  0.001 0.002 0.01 0.005 0.01 0.005 0.002 0.002],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_neurons': masked_array(data = [8 32 32 32 8 8 32 32 32 16 16 16 32 16 16 8 16 8 8 32],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'_optimizer': 'Adam',\n",
       "   'activator': 'tanh',\n",
       "   'batch_size': 64,\n",
       "   'dropout_rate1': 0.25,\n",
       "   'dropout_rate2': 0.25,\n",
       "   'epochs': 8,\n",
       "   'learning_rate': 0.005,\n",
       "   'neurons': 8},\n",
       "  {'_optimizer': 'Adam',\n",
       "   'activator': 'softmax',\n",
       "   'batch_size': 64,\n",
       "   'dropout_rate1': 0.25,\n",
       "   'dropout_rate2': 0.25,\n",
       "   'epochs': 12,\n",
       "   'learning_rate': 0.005,\n",
       "   'neurons': 32},\n",
       "  {'_optimizer': 'SGD',\n",
       "   'activator': 'softmax',\n",
       "   'batch_size': 16,\n",
       "   'dropout_rate1': 0.1,\n",
       "   'dropout_rate2': 0.5,\n",
       "   'epochs': 12,\n",
       "   'learning_rate': 0.002,\n",
       "   'neurons': 32},\n",
       "  {'_optimizer': 'Adamax',\n",
       "   'activator': 'relu',\n",
       "   'batch_size': 128,\n",
       "   'dropout_rate1': 0.0,\n",
       "   'dropout_rate2': 0.1,\n",
       "   'epochs': 8,\n",
       "   'learning_rate': 0.005,\n",
       "   'neurons': 32},\n",
       "  {'_optimizer': 'Nadam',\n",
       "   'activator': 'sigmoid',\n",
       "   'batch_size': 8,\n",
       "   'dropout_rate1': 0.25,\n",
       "   'dropout_rate2': 0.0,\n",
       "   'epochs': 4,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8},\n",
       "  {'_optimizer': 'Adamax',\n",
       "   'activator': 'relu',\n",
       "   'batch_size': 64,\n",
       "   'dropout_rate1': 0.25,\n",
       "   'dropout_rate2': 0.0,\n",
       "   'epochs': 8,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8},\n",
       "  {'_optimizer': 'SGD',\n",
       "   'activator': 'softmax',\n",
       "   'batch_size': 16,\n",
       "   'dropout_rate1': 0.0,\n",
       "   'dropout_rate2': 0.0,\n",
       "   'epochs': 12,\n",
       "   'learning_rate': 0.002,\n",
       "   'neurons': 32},\n",
       "  {'_optimizer': 'SGD',\n",
       "   'activator': 'sigmoid',\n",
       "   'batch_size': 128,\n",
       "   'dropout_rate1': 0.0,\n",
       "   'dropout_rate2': 0.25,\n",
       "   'epochs': 4,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32},\n",
       "  {'_optimizer': 'Adamax',\n",
       "   'activator': 'linear',\n",
       "   'batch_size': 8,\n",
       "   'dropout_rate1': 0.1,\n",
       "   'dropout_rate2': 0.0,\n",
       "   'epochs': 12,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32},\n",
       "  {'_optimizer': 'Adamax',\n",
       "   'activator': 'softmax',\n",
       "   'batch_size': 128,\n",
       "   'dropout_rate1': 0.1,\n",
       "   'dropout_rate2': 0.25,\n",
       "   'epochs': 4,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16},\n",
       "  {'_optimizer': 'Nadam',\n",
       "   'activator': 'sigmoid',\n",
       "   'batch_size': 32,\n",
       "   'dropout_rate1': 0.0,\n",
       "   'dropout_rate2': 0.25,\n",
       "   'epochs': 8,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16},\n",
       "  {'_optimizer': 'Adam',\n",
       "   'activator': 'softmax',\n",
       "   'batch_size': 64,\n",
       "   'dropout_rate1': 0.1,\n",
       "   'dropout_rate2': 0.0,\n",
       "   'epochs': 4,\n",
       "   'learning_rate': 0.005,\n",
       "   'neurons': 16},\n",
       "  {'_optimizer': 'Adam',\n",
       "   'activator': 'sigmoid',\n",
       "   'batch_size': 8,\n",
       "   'dropout_rate1': 0.0,\n",
       "   'dropout_rate2': 0.1,\n",
       "   'epochs': 12,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32},\n",
       "  {'_optimizer': 'SGD',\n",
       "   'activator': 'linear',\n",
       "   'batch_size': 16,\n",
       "   'dropout_rate1': 0.0,\n",
       "   'dropout_rate2': 0.25,\n",
       "   'epochs': 8,\n",
       "   'learning_rate': 0.002,\n",
       "   'neurons': 16},\n",
       "  {'_optimizer': 'Adam',\n",
       "   'activator': 'relu',\n",
       "   'batch_size': 64,\n",
       "   'dropout_rate1': 0.1,\n",
       "   'dropout_rate2': 0.0,\n",
       "   'epochs': 4,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16},\n",
       "  {'_optimizer': 'Nadam',\n",
       "   'activator': 'softmax',\n",
       "   'batch_size': 128,\n",
       "   'dropout_rate1': 0.0,\n",
       "   'dropout_rate2': 0.5,\n",
       "   'epochs': 12,\n",
       "   'learning_rate': 0.005,\n",
       "   'neurons': 8},\n",
       "  {'_optimizer': 'Adam',\n",
       "   'activator': 'relu',\n",
       "   'batch_size': 16,\n",
       "   'dropout_rate1': 0.0,\n",
       "   'dropout_rate2': 0.5,\n",
       "   'epochs': 4,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16},\n",
       "  {'_optimizer': 'Adamax',\n",
       "   'activator': 'relu',\n",
       "   'batch_size': 64,\n",
       "   'dropout_rate1': 0.25,\n",
       "   'dropout_rate2': 0.1,\n",
       "   'epochs': 12,\n",
       "   'learning_rate': 0.005,\n",
       "   'neurons': 8},\n",
       "  {'_optimizer': 'Adam',\n",
       "   'activator': 'sigmoid',\n",
       "   'batch_size': 64,\n",
       "   'dropout_rate1': 0.25,\n",
       "   'dropout_rate2': 0.1,\n",
       "   'epochs': 12,\n",
       "   'learning_rate': 0.002,\n",
       "   'neurons': 8},\n",
       "  {'_optimizer': 'SGD',\n",
       "   'activator': 'softmax',\n",
       "   'batch_size': 128,\n",
       "   'dropout_rate1': 0.25,\n",
       "   'dropout_rate2': 0.5,\n",
       "   'epochs': 4,\n",
       "   'learning_rate': 0.002,\n",
       "   'neurons': 32}),\n",
       " 'rank_test_score': array([ 5,  9, 18,  4, 13,  5, 18, 17,  7, 16, 14, 12,  3, 15,  2, 11,  8,\n",
       "         1, 10, 20], dtype=int32),\n",
       " 'split0_test_score': array([ 0.99067485,  0.99116564,  0.5207362 ,  0.99435583,  0.98699387,\n",
       "         0.99239264,  0.5207362 ,  0.5207362 ,  0.98944785,  0.96171779,\n",
       "         0.98503067,  0.98797546,  0.99435583,  0.98380368,  0.99411043,\n",
       "         0.98822086,  0.99141104,  0.99680982,  0.98748466,  0.5207362 ]),\n",
       " 'split0_train_score': array([ 0.99484536,  0.99288169,  0.50846834,  0.99619539,  0.98748159,\n",
       "         0.9945999 ,  0.50846834,  0.50846834,  0.99472263,  0.95949926,\n",
       "         0.98465881,  0.98649975,  0.99766814,  0.98367698,  0.99779087,\n",
       "         0.99140893,  0.99521355,  0.99570447,  0.98870889,  0.50846834]),\n",
       " 'split1_test_score': array([ 0.9904271 ,  0.98821797,  0.50220913,  0.99189985,  0.98453608,\n",
       "         0.99116348,  0.50220913,  0.50220913,  0.98993618,  0.95900835,\n",
       "         0.98159057,  0.98600884,  0.99165439,  0.98281787,  0.99165439,\n",
       "         0.98429062,  0.98478154,  0.99239077,  0.98723613,  0.50220913]),\n",
       " 'split1_train_score': array([ 0.99766843,  0.99484599,  0.51773224,  0.99889557,  0.99030556,\n",
       "         0.99840471,  0.51773224,  0.51773224,  0.99595042,  0.95987238,\n",
       "         0.98846484,  0.99251442,  0.99840471,  0.98588784,  0.99852743,\n",
       "         0.99104185,  0.98907841,  0.996564  ,  0.99300528,  0.51773224]),\n",
       " 'split2_test_score': array([ 0.9945999 ,  0.99018164,  0.51472754,  0.99361807,  0.98723613,\n",
       "         0.99214531,  0.51472754,  0.51472754,  0.99214531,  0.93667158,\n",
       "         0.9862543 ,  0.98527246,  0.99410898,  0.98429062,  0.99509082,\n",
       "         0.98846343,  0.99361807,  0.99410898,  0.99018164,  0.48527246]),\n",
       " 'split2_train_score': array([ 0.99754571,  0.9923917 ,  0.5114738 ,  0.998282  ,  0.9889557 ,\n",
       "         0.99680942,  0.5114738 ,  0.5114738 ,  0.99558228,  0.92845748,\n",
       "         0.98699227,  0.98821941,  0.997423  ,  0.98625598,  0.997423  ,\n",
       "         0.98993742,  0.99374156,  0.99852743,  0.99018284,  0.4885262 ]),\n",
       " 'std_fit_time': array([  0.66481455,   1.97294475,  11.20648578,   0.24150231,\n",
       "          0.32235277,   1.17472317,   7.55475786,   2.22687067,\n",
       "          7.99734372,   2.47265463,   3.25983587,   5.50528627,\n",
       "          3.26674952,   0.3016459 ,   0.98071838,   0.20004115,\n",
       "          0.19493245,   6.63185733,   0.52682899,   0.94550305]),\n",
       " 'std_score_time': array([ 0.04629536,  0.13925816,  0.13880691,  0.03223917,  0.01581686,\n",
       "         0.0510986 ,  0.94451137,  0.05485852,  0.07493426,  0.0907617 ,\n",
       "         0.07592037,  0.20954719,  0.05856045,  0.01416087,  0.09015234,\n",
       "         0.02719473,  0.04356234,  0.02738581,  0.02909826,  0.28252883]),\n",
       " 'std_test_score': array([ 0.00191132,  0.00122534,  0.00771774,  0.00102894,  0.0012197 ,\n",
       "         0.00053083,  0.00771774,  0.00771774,  0.00117354,  0.01122277,\n",
       "         0.00197426,  0.001141  ,  0.00121944,  0.00061262,  0.00144534,\n",
       "         0.00191242,  0.00375495,  0.00181893,  0.00133378,  0.01448318]),\n",
       " 'std_train_score': array([ 0.00130284,  0.00106051,  0.00385891,  0.00115573,  0.00115325,\n",
       "         0.00156004,  0.00385891,  0.00385891,  0.00051446,  0.01472197,\n",
       "         0.001567  ,  0.00252939,  0.00041719,  0.00113894,  0.00045918,\n",
       "         0.00062538,  0.00261516,  0.00118148,  0.00178256,  0.01218606])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just in case you want to see the parameters/combinations checked\n",
    "grid_result.cv_results_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
